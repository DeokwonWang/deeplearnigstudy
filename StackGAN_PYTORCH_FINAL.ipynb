{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackGAN-PYTORCH-FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpJio3ELkAfCF/uBndr5SD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeokwonWang/deeplearnigstudy/blob/main/StackGAN_PYTORCH_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnDTNMa3xT2p",
        "outputId": "7240a5a1-b4e5-40db-bd96-000ae5a94d7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmb5r6-dIK8j"
      },
      "source": [
        "!cd /content/drive/MyDrive\n",
        "# !git clone https://github.com/hanzhanggit/StackGAN-Pytorch.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0t0bANqITXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65874c53-1331-4703-e0b1-9ee5bb77cd0d"
      },
      "source": [
        "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install torchvision tensorboard python-dateutil easydict pandas torchfile tensorboardX"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (54.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=0e07c0af17cf109d648c506b5d4518bfc5e4968a9cf16edd85d932cd4898bef3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built torchfile\n",
            "Installing collected packages: torchfile, tensorboardX\n",
            "Successfully installed tensorboardX-2.2 torchfile-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltAfAtyBxdDk",
        "outputId": "30095536-278e-4d5a-b684-2c3f6610e857"
      },
      "source": [
        "cd /content/drive/MyDrive/StackGAN-Pytorch/code"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackGAN-Pytorch/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2jlkrvhxw9N",
        "outputId": "8f316333-6d75-4d32-aa6f-38b0e7ae56cb"
      },
      "source": [
        "\"\"\"\n",
        "!gdown --id 0B3y_msrWZaXLQXVzOENCY2E3TlU\n",
        "!gdown --id 0B3y_msrWZaXLeEs5MTg0RC1fa0U\n",
        "\n",
        "!unzip coco.zip\n",
        "!unzip coco_test.zip -d coco/\n",
        "\n",
        "!rm coco.zip coco_test.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip train2014.zip -d coco/\n",
        "!rm train2014.zip\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "#!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!unzip val2014.zip -d coco/\n",
        "!rm val2014.zip\n",
        "\n",
        "#!wget http://images.cocodataset.org/zips/test2014.zip\n",
        "!unzip test2014.zip -d coco/\n",
        "!rm test2014.zip\n",
        "\n",
        "#!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip annotations_trainval2014.zip -d coco/\n",
        "!rm annotations_trainval2014.zip\n",
        "\n",
        "#!wget http://images.cocodataset.org/annotations/image_info_test2014.zip\n",
        "!unzip image_info_test2014.zip -d coco/\n",
        "!rm image_info_test2014.zip\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open val2014.zip, val2014.zip.zip or val2014.zip.ZIP.\n",
            "rm: cannot remove 'val2014.zip': No such file or directory\n",
            "unzip:  cannot find or open test2014.zip, test2014.zip.zip or test2014.zip.ZIP.\n",
            "rm: cannot remove 'test2014.zip': No such file or directory\n",
            "unzip:  cannot find or open annotations_trainval2014.zip, annotations_trainval2014.zip.zip or annotations_trainval2014.zip.ZIP.\n",
            "rm: cannot remove 'annotations_trainval2014.zip': No such file or directory\n",
            "unzip:  cannot find or open image_info_test2014.zip, image_info_test2014.zip.zip or image_info_test2014.zip.ZIP.\n",
            "rm: cannot remove 'image_info_test2014.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpodzqHfJDFC"
      },
      "source": [
        "/models 안에 coco/ 폴더 만들어야됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgLZcoteHTE4"
      },
      "source": [
        "# !cd /content/drive/MyDrive/StackGAN-Pytorch/models/coco\n",
        "# !gdown --id 0B3y_msrWZaXLYjNra2ZSSmtVQlE"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzqZsNUrIw_T"
      },
      "source": [
        "파일이름 수정 => 앞 부분의 coco_를 지움"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGXxX0wkIuxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3e4191-aa4b-45bc-bbcd-39692b53cd2c"
      },
      "source": [
        "!python main.py --cfg cfg/coco_eval.yml --gpu 0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'CONFIG_NAME': 'stageII',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'coco',\n",
            " 'DATA_DIR': '../data/coco',\n",
            " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
            " 'GAN': {'CONDITION_DIM': 128, 'DF_DIM': 96, 'GF_DIM': 192, 'R_NUM': 2},\n",
            " 'GPU_ID': '0',\n",
            " 'IMSIZE': 256,\n",
            " 'NET_D': '',\n",
            " 'NET_G': '../models/coco/netG_epoch_90.pth',\n",
            " 'STAGE': 2,\n",
            " 'STAGE1_G': '',\n",
            " 'TEXT': {'DIMENSION': 1024},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'COEFF': {'KL': 2.0},\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'FLAG': False,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'LR_DECAY_EPOCH': 600,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'PRETRAINED_EPOCH': 600,\n",
            "           'PRETRAINED_MODEL': '',\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'VIS_COUNT': 64,\n",
            " 'WORKERS': 4,\n",
            " 'Z_DIM': 100}\n",
            "STAGE2_G(\n",
            "  (STAGE1_G): STAGE1_G(\n",
            "    (ca_net): CA_NET(\n",
            "      (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=228, out_features=24576, bias=False)\n",
            "      (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample2): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample3): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample4): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (img): Sequential(\n",
            "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (ca_net): CA_NET(\n",
            "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "  )\n",
            "  (hr_joint): Sequential(\n",
            "    (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (residual): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upsample1): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample2): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample3): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample4): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (img): Sequential(\n",
            "    (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "Load from:  ../models/coco/netG_epoch_90.pth\n",
            "STAGE2_D(\n",
            "  (encode_img): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(768, 1536, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Conv2d(1536, 3072, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (17): Conv2d(3072, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (20): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (get_cond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (4): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (get_uncond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Successfully load sentences from:  ../data/coco/test/val_captions.t7\n",
            "Total number of sentences: 40470\n",
            "num_embeddings: 40470 (40470, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfLgzL8RJRlo"
      },
      "source": [
        "오류 1. code/trainer.py 내의 filewriter 앞 tensorboard -> tensorboardX 로 수정\\\n",
        "오류 2. code/miscc/config.py 내의 a.iteritem() -> a.item()으로 수정\\\n",
        "오류 3. code/miscc/config.py 내의 not b.has_key(k)를 k not in b 로 수정"
      ]
    }
  ]
}