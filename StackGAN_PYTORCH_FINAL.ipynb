{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackGAN-PYTORCH-FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzWu2ZDO04/TGgpA74AT/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeokwonWang/deeplearnigstudy/blob/main/StackGAN_PYTORCH_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnDTNMa3xT2p",
        "outputId": "6a922f55-3eb2-4c24-a9a9-afc75d167cbe"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmb5r6-dIK8j"
      },
      "source": [
        "cd /content/drive/MyDrive\r\n",
        "!git clone https://github.com/hanzhanggit/StackGAN-Pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0t0bANqITXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59c8dc3-37c3-46cf-eef2-930845e719c6"
      },
      "source": [
        "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\r\n",
        "!pip install torchvision tensorboard python-dateutil easydict pandas torchfile tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.7.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.27.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltAfAtyBxdDk",
        "outputId": "47df7159-504b-45c3-baf6-eca3ada4d456"
      },
      "source": [
        "cd /content/drive/MyDrive/StackGAN-Pytorch/code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/StackGAN-Pytorch/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2jlkrvhxw9N",
        "outputId": "8f316333-6d75-4d32-aa6f-38b0e7ae56cb"
      },
      "source": [
        "\"\"\"\r\n",
        "!gdown --id 0B3y_msrWZaXLQXVzOENCY2E3TlU\r\n",
        "!gdown --id 0B3y_msrWZaXLeEs5MTg0RC1fa0U\r\n",
        "\r\n",
        "!unzip coco.zip\r\n",
        "!unzip coco_test.zip -d coco/\r\n",
        "\r\n",
        "!rm coco.zip coco_test.zip\r\n",
        "\r\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\r\n",
        "!unzip train2014.zip -d coco/\r\n",
        "!rm train2014.zip\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "#!wget http://images.cocodataset.org/zips/val2014.zip\r\n",
        "!unzip val2014.zip -d coco/\r\n",
        "!rm val2014.zip\r\n",
        "\r\n",
        "#!wget http://images.cocodataset.org/zips/test2014.zip\r\n",
        "!unzip test2014.zip -d coco/\r\n",
        "!rm test2014.zip\r\n",
        "\r\n",
        "#!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\r\n",
        "!unzip annotations_trainval2014.zip -d coco/\r\n",
        "!rm annotations_trainval2014.zip\r\n",
        "\r\n",
        "#!wget http://images.cocodataset.org/annotations/image_info_test2014.zip\r\n",
        "!unzip image_info_test2014.zip -d coco/\r\n",
        "!rm image_info_test2014.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open val2014.zip, val2014.zip.zip or val2014.zip.ZIP.\n",
            "rm: cannot remove 'val2014.zip': No such file or directory\n",
            "unzip:  cannot find or open test2014.zip, test2014.zip.zip or test2014.zip.ZIP.\n",
            "rm: cannot remove 'test2014.zip': No such file or directory\n",
            "unzip:  cannot find or open annotations_trainval2014.zip, annotations_trainval2014.zip.zip or annotations_trainval2014.zip.ZIP.\n",
            "rm: cannot remove 'annotations_trainval2014.zip': No such file or directory\n",
            "unzip:  cannot find or open image_info_test2014.zip, image_info_test2014.zip.zip or image_info_test2014.zip.ZIP.\n",
            "rm: cannot remove 'image_info_test2014.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpodzqHfJDFC"
      },
      "source": [
        "/models 안에 coco/ 폴더 만들어야됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgLZcoteHTE4"
      },
      "source": [
        "cd /content/drive/MyDrive/StackGAN-Pytorch/models/coco\r\n",
        "!gdown --id 0B3y_msrWZaXLYjNra2ZSSmtVQlE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzqZsNUrIw_T"
      },
      "source": [
        "파일이름 수정 => 앞 부분의 coco_를 지움"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGXxX0wkIuxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868e096b-74c4-40c8-df93-ed5f92bb9275"
      },
      "source": [
        "!python main.py --cfg cfg/coco_eval.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'CONFIG_NAME': 'stageII',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'coco',\n",
            " 'DATA_DIR': '../data/coco',\n",
            " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
            " 'GAN': {'CONDITION_DIM': 128, 'DF_DIM': 96, 'GF_DIM': 192, 'R_NUM': 2},\n",
            " 'GPU_ID': '0',\n",
            " 'IMSIZE': 256,\n",
            " 'NET_D': '',\n",
            " 'NET_G': '../models/coco/netG_epoch_90.pth',\n",
            " 'STAGE': 2,\n",
            " 'STAGE1_G': '',\n",
            " 'TEXT': {'DIMENSION': 1024},\n",
            " 'TRAIN': {'BATCH_SIZE': 40,\n",
            "           'COEFF': {'KL': 2.0},\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'FLAG': False,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'LR_DECAY_EPOCH': 600,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'PRETRAINED_EPOCH': 600,\n",
            "           'PRETRAINED_MODEL': '',\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'VIS_COUNT': 64,\n",
            " 'WORKERS': 4,\n",
            " 'Z_DIM': 100}\n",
            "STAGE2_G(\n",
            "  (STAGE1_G): STAGE1_G(\n",
            "    (ca_net): CA_NET(\n",
            "      (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=228, out_features=24576, bias=False)\n",
            "      (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample2): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample3): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample4): Sequential(\n",
            "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "    (img): Sequential(\n",
            "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (ca_net): CA_NET(\n",
            "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "  )\n",
            "  (hr_joint): Sequential(\n",
            "    (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (residual): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upsample1): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample2): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample3): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (upsample4): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (img): Sequential(\n",
            "    (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): Tanh()\n",
            "  )\n",
            ")\n",
            "Load from:  ../models/coco/netG_epoch_90.pth\n",
            "STAGE2_D(\n",
            "  (encode_img): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(768, 1536, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (14): Conv2d(1536, 3072, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (17): Conv2d(3072, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (20): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (get_cond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (4): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (get_uncond_logits): D_GET_LOGITS(\n",
            "    (outlogits): Sequential(\n",
            "      (0): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Successfully load sentences from:  ../data/coco/test/val_captions.t7\n",
            "Total number of sentences: 40470\n",
            "num_embeddings: 40470 (40470, 1024)\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 77, in <module>\n",
            "    algo.sample(datapath, cfg.STAGE)\n",
            "  File \"/content/drive/MyDrive/StackGAN-Pytorch/code/trainer.py\", line 278, in sample\n",
            "    nn.parallel.data_parallel(netG, inputs, self.gpus)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 215, in data_parallel\n",
            "    return module(*inputs[0], **module_kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/StackGAN-Pytorch/code/model.py\", line 256, in forward\n",
            "    h_code = self.upsample3(h_code)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 117, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\", line 136, in forward\n",
            "    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 2058, in batch_norm\n",
            "    training, momentum, eps, torch.backends.cudnn.enabled\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 7.43 GiB total capacity; 6.41 GiB already allocated; 152.81 MiB free; 6.66 GiB reserved in total by PyTorch)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfLgzL8RJRlo"
      },
      "source": [
        "오류 1. code/trainer.py 내의 filewriter 앞 tensorboard -> tensorboardX 로 수정\\\r\n",
        "오류 2. code/miscc/config.py 내의 a.iteritem() -> a.item()으로 수정\\\r\n",
        "오류 3. code/miscc/config.py 내의 not b.has_key(k)를 k not in b 로 수정"
      ]
    }
  ]
}